{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.14996032e-19,  7.06297091e-04,  7.58941521e-19, ...,\n",
       "         2.58670332e-03, -5.42101086e-19,  4.33680869e-19],\n",
       "       [ 8.13151629e-20,  1.12761410e-02, -1.08420217e-19, ...,\n",
       "         1.08420217e-18,  1.67655157e-03, -1.08420217e-19],\n",
       "       [ 4.87890978e-19,  7.11666893e-04,  7.99320852e-04, ...,\n",
       "         6.75588570e-04, -1.62630326e-19,  8.78898247e-04],\n",
       "       ...,\n",
       "       [-2.71050543e-20,  3.46944695e-18,  1.08420217e-19, ...,\n",
       "         1.30104261e-18, -2.16840434e-19,  3.70953831e-03],\n",
       "       [-8.13151629e-20,  3.46944695e-18,  2.16840434e-19, ...,\n",
       "         1.30104261e-18, -2.71050543e-19,  2.16840434e-19],\n",
       "       [ 2.38292463e-03,  9.91981445e-02,  1.15335927e-03, ...,\n",
       "        -2.16840434e-19, -3.25260652e-19,  5.42101086e-19]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/tdidf_vector.pkl', 'rb') as f_open:\n",
    "    tfidf_matrix = pkl.load(f_open)\n",
    "\n",
    "clustering = KMeans(n_clusters=8).fit(tfidf_matrix.toarray())\n",
    "clustering.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 2, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 4, 4, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 1,\n",
       "       5, 2, 2, 2, 2, 5, 5, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2,\n",
       "       2, 2, 5, 5, 2, 2, 1, 2, 2, 1, 4, 4, 2, 2, 5, 2, 5, 2, 5, 5, 4, 5,\n",
       "       5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 2, 4, 5, 2, 4, 5, 5, 4, 4, 2, 2,\n",
       "       2, 2, 1, 2, 2, 2, 2, 5, 5, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 4,\n",
       "       2, 2, 5, 5, 5, 5, 5, 5, 5, 2, 4, 2, 2, 1, 4, 5, 2, 4, 4, 4, 4, 4,\n",
       "       4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
       "       4, 0, 0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 6, 0,\n",
       "       0, 0, 1, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 4, 0, 0, 5,\n",
       "       5, 2, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 0, 1, 2,\n",
       "       0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2,\n",
       "       0, 1, 1, 1, 5, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 5, 2, 0, 2, 1, 0, 0, 0, 2, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 1, 0, 0, 0, 2,\n",
       "       2, 0, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 0,\n",
       "       5, 0, 0, 0, 0, 7, 0, 2, 0, 0, 1, 3, 0, 0, 0, 7, 3, 3, 3, 3, 3, 3,\n",
       "       7, 3, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 3, 3, 3, 3, 7, 3, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 3, 7, 3, 7, 3, 7, 3, 7, 7, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 7, 3, 3, 3, 7, 7, 7, 7, 3, 3, 7, 7, 7, 7, 7, 3, 7, 3, 3, 3, 3,\n",
       "       3, 3, 3, 7, 3, 3, 3, 7, 7, 7, 3, 7, 7, 1, 1, 1, 3, 1, 1, 3, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 3, 1, 3, 3, 2, 7, 7, 3, 2, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 8266)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from random  import randrange\n",
    "tfidf_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DIST = 1e10\n",
    "\n",
    "class KMeans():\n",
    "    \"\"\"\n",
    "    Agglomerative Clustering\n",
    "    Recursively merges the pair of clusters that minimally increases\n",
    "    a given linkage distance.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=8, iters=300):\n",
    "        self._n_clusters = n_clusters\n",
    "        self._iters = iters\n",
    "        self._dist_mat = None\n",
    "        \n",
    "    def distance_matrix(self, X):\n",
    "        \"\"\"\n",
    "        Computer matrix of exponential cosine distance between each data point.\n",
    "        \"\"\"\n",
    "        self._dist_mat = np.zeros((X.shape[0], X.shape[0]))\n",
    "#       calculating cosine distances\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                if i!=j:\n",
    "                    self._dist_mat[i][j] = self.cos_sim_dist(X[i],X[j])\n",
    "        np.fill_diagonal(self._dist_mat, MIN_DIST)\n",
    "#         print(self._dist_mat[545][545])\n",
    "#         print(self._dist_mat.shape)\n",
    "        \n",
    "    @staticmethod\n",
    "    def cos_sim_dist(X,Y):\n",
    "        \"\"\"\n",
    "        Return exponential cosine similarity between two vectors.\n",
    "        \"\"\"\n",
    "        return np.exp(-1 * ((X @ Y.T)/(norm(X)*norm(Y))))\n",
    "    \n",
    "    def init_centroids(self, X):\n",
    "        \"\"\"\n",
    "        Create random centroids.\n",
    "        \"\"\"\n",
    "        np.random.RandomState(randrange(0, 1e4))\n",
    "        self._centroids = X[np.random.choice(X.shape[0], self._n_clusters, replace=False)]\n",
    "        \n",
    "    def closest_centroid(self, X):\n",
    "        \"\"\"\n",
    "        Return index of centroid closest to the given X vector.\n",
    "        \"\"\"\n",
    "        min_dist_list = [self.cos_sim_dist(X, Y) for Y in self._centroids]\n",
    "        return min_dist_list.index(min(min_dist_list))   \n",
    "            \n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Method to call to fit data.\n",
    "        \"\"\"\n",
    "        X_arr = X.toarray()\n",
    "        self.init_centroids(X_arr)\n",
    "        self.distance_matrix(X_arr)\n",
    "        doc_labels = np.zeros((X_arr.shape[0], 1))\n",
    "        for i in range(self._iters):\n",
    "            centroid_points = [[] for _ in range(self._n_clusters)]\n",
    "            print(f\"Iteration number {i}\", end=\"\\r\")\n",
    "            for index, arr in enumerate(X_arr):\n",
    "#                 assign closest centroid\n",
    "                doc_labels[index] = self.closest_centroid(arr)\n",
    "                for num in doc_labels[index]:\n",
    "                    centroid_points[int(num)].append(index)\n",
    "                \n",
    "    #             compute new centroids\n",
    "            new_centroids = np.zeros((self._n_clusters, X_arr.shape[1]))\n",
    "            for ind in range(self._n_clusters):\n",
    "                new_centroids[ind, :] = np.mean(np.take(X_arr, centroid_points[ind], axis=0), axis=0)\n",
    "            \n",
    "#             break if no change detected\n",
    "            if np.all(self._centroids == new_centroids):\n",
    "                break\n",
    "            self._centroids = new_centroids\n",
    "        self._results = [[] for _ in range(self._n_clusters)]\n",
    "        for i, ele in enumerate(doc_labels):\n",
    "            for num in ele:\n",
    "                print(num)\n",
    "                self._results[int(num)].append(i)\n",
    "        print(self._results)\n",
    "        self.save()\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the results in a sorted manner to ../clusters/agglomerative.txt\n",
    "        \"\"\"\n",
    "        sorted_results = sorted(self._results, key= lambda x: min(x))\n",
    "        sorted_results = [sorted(x) for x in sorted_results]\n",
    "#         print(sorted_results)\n",
    "        with open(\"../clusters/kmeans.txt\", 'w') as f_open:\n",
    "            for result in sorted_results:\n",
    "                f_open.write(','.join([str(x) for x in result]))\n",
    "                f_open.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "kmeans.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Assignment_3",
   "language": "python",
   "name": "assignment_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
