{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.13151629e-20,  3.46944695e-18,  2.16840434e-19, ...,\n",
       "         1.30104261e-18, -2.71050543e-19,  4.20615590e-03],\n",
       "       [ 2.02187545e-03,  9.90770502e-02,  9.78607865e-04, ...,\n",
       "        -1.08420217e-18,  8.12873487e-04,  5.42101086e-19],\n",
       "       [-4.33680869e-19,  2.10154150e-03,  6.50521303e-19, ...,\n",
       "         2.31115166e-03, -4.87890978e-19,  7.58941521e-19],\n",
       "       ...,\n",
       "       [-5.14996032e-19, -1.38777878e-17,  7.58941521e-19, ...,\n",
       "        -3.03576608e-18, -5.42101086e-19,  1.08775935e-03],\n",
       "       [-8.13151629e-20,  3.46944695e-18,  2.16840434e-19, ...,\n",
       "         2.62943833e-03, -2.71050543e-19,  2.16840434e-19],\n",
       "       [-4.87890978e-19,  3.46944695e-18,  1.46057719e-03, ...,\n",
       "         1.23448457e-03, -5.42101086e-19,  8.67361738e-19]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/tdidf_vector.pkl', 'rb') as f_open:\n",
    "    tfidf_matrix = pkl.load(f_open)\n",
    "\n",
    "clustering = KMeans(n_clusters=8).fit(tfidf_matrix.toarray())\n",
    "clustering.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 6, 6, 5, 5, 5, 5, 7, 6, 6, 7, 7, 7, 6, 6, 6, 7, 7, 7, 7, 5,\n",
       "       5, 7, 7, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 7, 7, 7, 7, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       5, 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "       7, 7, 7, 7, 7, 4, 7, 7, 6, 7, 0, 7, 7, 7, 7, 7, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 4, 4, 4, 4, 4, 4, 5, 5, 5, 7, 0, 6, 0, 0, 0, 7, 7, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 7, 7, 0, 0, 4,\n",
       "       7, 4, 4, 4, 4, 4, 5, 5, 0, 7, 4, 4, 5, 4, 5, 4, 5, 4, 5, 5, 4, 4,\n",
       "       5, 7, 6, 0, 6, 5, 4, 5, 5, 5, 7, 5, 0, 5, 7, 4, 5, 5, 4, 5, 5, 6,\n",
       "       0, 4, 5, 5, 5, 5, 4, 5, 5, 5, 0, 5, 4, 5, 5, 5, 5, 5, 5, 4, 4, 2,\n",
       "       2, 5, 5, 5, 5, 4, 4, 5, 4, 4, 4, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 5, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 6,\n",
       "       4, 5, 2, 2, 2, 2, 2, 5, 7, 7, 5, 2, 2, 2, 5, 5, 2, 5, 7, 7, 6, 5,\n",
       "       5, 5, 5, 6, 6, 5, 5, 5, 2, 5, 5, 2, 5, 4, 2, 2, 5, 5, 4, 2, 5, 2,\n",
       "       2, 5, 2, 5, 4, 5, 7, 2, 2, 2, 5, 2, 2, 7, 5, 2, 5, 5, 5, 2, 5, 5,\n",
       "       5, 2, 5, 5, 2, 2, 5, 5, 5, 2, 5, 2, 5, 6, 2, 2, 2, 5, 5, 2, 0, 5,\n",
       "       2, 5, 5, 5, 5, 2, 2, 5, 2, 6, 5, 6, 6, 5, 5, 2, 2, 2, 2, 6, 2, 2,\n",
       "       2, 2, 5, 2, 7, 5, 2, 5, 0, 4, 2, 2, 5, 6, 2, 2, 7, 7, 2, 2, 7, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5,\n",
       "       5, 2, 7, 2, 2, 2, 5, 5, 5, 5, 2, 2, 5, 2, 5, 5, 7, 5, 2, 7, 5, 5,\n",
       "       5, 2, 2, 2, 2, 1, 2, 5, 5, 5, 5, 3, 2, 5, 2, 1, 3, 3, 3, 3, 3, 3,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 1, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 1, 3, 3, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 3, 1, 3, 3, 3, 3,\n",
       "       3, 3, 3, 1, 3, 3, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 3, 1, 3, 3, 1, 1, 1, 3, 7, 3, 3], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 8266)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from random  import randrange\n",
    "tfidf_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DIST = 1e10\n",
    "\n",
    "class KMeans():\n",
    "    \"\"\"\n",
    "    Agglomerative Clustering\n",
    "    Recursively merges the pair of clusters that minimally increases\n",
    "    a given linkage distance.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=8, iters=300, path=\"../clusters/kmeans.txt\"):\n",
    "        self._n_clusters = n_clusters\n",
    "        self._iters = iters\n",
    "        self._path = path\n",
    "        self._dist_mat = None\n",
    "        \n",
    "    def distance_matrix(self, X):\n",
    "        \"\"\"\n",
    "        Computer matrix of exponential cosine distance between each data point.\n",
    "        \"\"\"\n",
    "        self._dist_mat = np.zeros((X.shape[0], X.shape[0]))\n",
    "#       calculating cosine distances\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                if i!=j:\n",
    "                    self._dist_mat[i][j] = self.cos_sim_dist(X[i],X[j])\n",
    "        np.fill_diagonal(self._dist_mat, MIN_DIST)\n",
    "#         print(self._dist_mat[545][545])\n",
    "#         print(self._dist_mat.shape)\n",
    "        \n",
    "    @staticmethod\n",
    "    def cos_sim_dist(X,Y):\n",
    "        \"\"\"\n",
    "        Return exponential cosine similarity between two vectors.\n",
    "        \"\"\"\n",
    "        return np.exp(-1 * ((X @ Y.T)/(norm(X)*norm(Y))))\n",
    "    \n",
    "    def init_centroids(self, X):\n",
    "        \"\"\"\n",
    "        Create random centroids.\n",
    "        \"\"\"\n",
    "        np.random.RandomState(randrange(0, 1e4))\n",
    "        self._centroids = X[np.random.choice(X.shape[0], self._n_clusters, replace=False)]\n",
    "        \n",
    "    def closest_centroid(self, X):\n",
    "        \"\"\"\n",
    "        Return index of centroid closest to the given X vector.\n",
    "        \"\"\"\n",
    "        min_dist_list = [self.cos_sim_dist(X, Y) for Y in self._centroids]\n",
    "        return min_dist_list.index(min(min_dist_list))   \n",
    "            \n",
    "    \n",
    "    def fit(self, X_arr):\n",
    "        \"\"\"\n",
    "        Method to call to fit data.\n",
    "        \"\"\"\n",
    "        self.init_centroids(X_arr)\n",
    "        self.distance_matrix(X_arr)\n",
    "        doc_labels = np.zeros((X_arr.shape[0], 1))\n",
    "        for i in range(self._iters):\n",
    "            centroid_points = [[] for _ in range(self._n_clusters)]\n",
    "            print(f\"Iteration number {i}\", end=\"\\r\")\n",
    "            for index, arr in enumerate(X_arr):\n",
    "#                 assign closest centroid\n",
    "                doc_labels[index] = self.closest_centroid(arr)\n",
    "                for num in doc_labels[index]:\n",
    "                    centroid_points[int(num)].append(index)\n",
    "                \n",
    "    #             compute new centroids\n",
    "            new_centroids = np.zeros((self._n_clusters, X_arr.shape[1]))\n",
    "            for ind in range(self._n_clusters):\n",
    "                new_centroids[ind, :] = np.mean(np.take(X_arr, centroid_points[ind], axis=0), axis=0)\n",
    "            \n",
    "#             break if no change detected\n",
    "            if np.all(self._centroids == new_centroids):\n",
    "                break\n",
    "            self._centroids = new_centroids\n",
    "        self._results = [[] for _ in range(self._n_clusters)]\n",
    "        for i, ele in enumerate(doc_labels):\n",
    "            for num in ele:\n",
    "                print(num)\n",
    "                self._results[int(num)].append(i)\n",
    "        print(self._results)\n",
    "        self.save()\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the results in a sorted manner to ../clusters/agglomerative.txt\n",
    "        \"\"\"\n",
    "        sorted_results = sorted(self._results, key= lambda x: min(x))\n",
    "        sorted_results = [sorted(x) for x in sorted_results]\n",
    "#         print(sorted_results)\n",
    "        with open(self._path, 'w') as f_open:\n",
    "            for result in sorted_results:\n",
    "                f_open.write(','.join([str(x) for x in result]))\n",
    "                f_open.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0ration number 9\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "7.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "4.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "5.0\n",
      "5.0\n",
      "7.0\n",
      "2.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "4.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "1.0\n",
      "5.0\n",
      "2.0\n",
      "4.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "4.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "2.0\n",
      "7.0\n",
      "2.0\n",
      "2.0\n",
      "6.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "4.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "4.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "0.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "4.0\n",
      "4.0\n",
      "2.0\n",
      "2.0\n",
      "4.0\n",
      "4.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "6.0\n",
      "7.0\n",
      "6.0\n",
      "6.0\n",
      "4.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "2.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "3.0\n",
      "4.0\n",
      "1.0\n",
      "4.0\n",
      "4.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "1.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "4.0\n",
      "0.0\n",
      "0.0\n",
      "4.0\n",
      "7.0\n",
      "7.0\n",
      "0.0\n",
      "6.0\n",
      "6.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "3.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "1.0\n",
      "7.0\n",
      "1.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "6.0\n",
      "4.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "5.0\n",
      "6.0\n",
      "3.0\n",
      "4.0\n",
      "6.0\n",
      "7.0\n",
      "4.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "4.0\n",
      "6.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "1.0\n",
      "6.0\n",
      "4.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "7.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "2.0\n",
      "4.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "4.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "3.0\n",
      "4.0\n",
      "6.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "3.0\n",
      "5.0\n",
      "4.0\n",
      "1.0\n",
      "4.0\n",
      "3.0\n",
      "3.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "5.0\n",
      "6.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "1.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "7.0\n",
      "1.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "3.0\n",
      "1.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "5.0\n",
      "1.0\n",
      "4.0\n",
      "1.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "6.0\n",
      "5.0\n",
      "3.0\n",
      "6.0\n",
      "5.0\n",
      "6.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "5.0\n",
      "3.0\n",
      "6.0\n",
      "5.0\n",
      "5.0\n",
      "3.0\n",
      "4.0\n",
      "6.0\n",
      "5.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "1.0\n",
      "7.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "5.0\n",
      "0.0\n",
      "5.0\n",
      "5.0\n",
      "7.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "5.0\n",
      "1.0\n",
      "6.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "1.0\n",
      "3.0\n",
      "1.0\n",
      "3.0\n",
      "7.0\n",
      "2.0\n",
      "7.0\n",
      "3.0\n",
      "5.0\n",
      "4.0\n",
      "4.0\n",
      "3.0\n",
      "7.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "3.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "3.0\n",
      "3.0\n",
      "7.0\n",
      "3.0\n",
      "3.0\n",
      "5.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "5.0\n",
      "6.0\n",
      "5.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "6.0\n",
      "3.0\n",
      "3.0\n",
      "6.0\n",
      "3.0\n",
      "7.0\n",
      "4.0\n",
      "3.0\n",
      "3.0\n",
      "5.0\n",
      "7.0\n",
      "6.0\n",
      "6.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "3.0\n",
      "5.0\n",
      "0.0\n",
      "7.0\n",
      "5.0\n",
      "0.0\n",
      "5.0\n",
      "6.0\n",
      "0.0\n",
      "5.0\n",
      "5.0\n",
      "7.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "[[89, 102, 165, 166, 168, 169, 173, 372, 467, 470, 473, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588], [0, 1, 2, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 61, 144, 155, 200, 202, 248, 294, 304, 306, 307, 318, 328, 329, 333, 335, 365, 383, 385, 399, 401], [26, 45, 47, 48, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 116, 117, 120, 121, 122, 123, 124, 125, 135, 269, 273, 386, 404], [14, 50, 56, 139, 140, 142, 147, 176, 190, 220, 221, 222, 228, 251, 271, 272, 275, 276, 285, 291, 296, 297, 327, 330, 331, 343, 354, 358, 387, 400, 402, 406, 410, 412, 413, 419, 428, 429, 431, 432, 434, 435, 436, 450, 451, 453, 456, 457, 465], [17, 18, 34, 46, 55, 87, 93, 114, 115, 118, 119, 130, 136, 138, 141, 143, 145, 146, 148, 151, 152, 153, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 167, 170, 177, 178, 180, 181, 183, 184, 185, 186, 187, 189, 194, 196, 197, 198, 199, 203, 204, 205, 207, 208, 209, 210, 212, 213, 215, 217, 219, 223, 229, 232, 238, 239, 240, 242, 245, 246, 247, 250, 252, 253, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 270, 274, 277, 278, 279, 280, 281, 282, 283, 284, 286, 293, 295, 311, 312, 313, 314, 324, 325, 326, 334, 359, 393, 394, 408, 409, 414, 415, 416, 455, 462], [23, 24, 44, 149, 150, 224, 226, 241, 288, 289, 290, 292, 298, 299, 300, 302, 308, 309, 315, 316, 319, 320, 321, 322, 323, 332, 336, 337, 338, 339, 342, 345, 347, 353, 356, 357, 361, 367, 368, 369, 371, 373, 374, 379, 380, 382, 388, 389, 390, 391, 392, 395, 396, 397, 398, 407, 417, 418, 420, 421, 422, 423, 425, 426, 427, 433, 437, 443, 445, 458, 463, 466, 469, 471, 474, 475], [4, 41, 66, 126, 128, 129, 131, 132, 133, 134, 137, 174, 175, 179, 182, 188, 191, 192, 193, 195, 206, 211, 214, 216, 218, 225, 227, 230, 233, 234, 235, 236, 237, 243, 244, 249, 255, 287, 301, 303, 305, 310, 340, 341, 344, 346, 348, 350, 351, 352, 355, 360, 370, 376, 377, 378, 381, 384, 424, 438, 444, 446, 447, 448, 449, 452, 460, 461, 464, 472], [6, 25, 63, 127, 171, 172, 201, 231, 254, 317, 349, 362, 363, 364, 366, 375, 403, 405, 411, 430, 439, 440, 441, 442, 454, 459, 468, 476]]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans()\n",
    "kmeans.fit(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Assignment_3",
   "language": "python",
   "name": "assignment_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
