{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 4, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 3, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/tdidf_vector.pkl', 'rb') as f_open:\n",
    "    tfidf_matrix = pkl.load(f_open)\n",
    "\n",
    "clustering = AgglomerativeClustering(n_clusters=8, affinity='cosine', \n",
    "                                    linkage=\"single\").fit(tfidf_matrix.toarray())\n",
    "print(clustering.n_clusters_)\n",
    "clustering.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22.2.post1\n"
     ]
    }
   ],
   "source": [
    "from sklearn import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 8266)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "tfidf_matrix.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DIST = 1e10\n",
    "VEC_IND = 0\n",
    "IND_IND = 1\n",
    "\n",
    "class AgglomerativeClustering():\n",
    "    \"\"\"\n",
    "    Agglomerative Clustering\n",
    "    Recursively merges the pair of clusters that minimally increases\n",
    "    a given linkage distance.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=8, affinity='cosine', linkage='single', path=\"../clusters/agglomerative.txt\"):\n",
    "        self._n_clusters = n_clusters\n",
    "        self._affinity = affinity\n",
    "        self._linkage = linkage\n",
    "        self._path = path\n",
    "        self._dist_mat = None\n",
    "        \n",
    "    @staticmethod\n",
    "    def cos_sim(X,Y):\n",
    "        \"\"\"\n",
    "        Return cosine similarity between two vectors.\n",
    "        \"\"\"\n",
    "        return (X @ Y.T)/(norm(X)*norm(Y))\n",
    "    \n",
    "    def distance_matrix(self, X):\n",
    "        \"\"\"\n",
    "        Computer matrix of exponential cosine distance between each data point.\n",
    "        \"\"\"\n",
    "        self._dist_mat = np.zeros((X.shape[0], X.shape[0]))\n",
    "#       calculating cosine distances\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                if i!=j:\n",
    "                    self._dist_mat[i][j] = np.exp(-1*self.cos_sim(X[i],X[j]))\n",
    "        np.fill_diagonal(self._dist_mat, MIN_DIST)\n",
    "#         print(self._dist_mat[545][545])\n",
    "#         print(self._dist_mat.shape)\n",
    "    \n",
    "    def merge_clusters(self, X,Y):\n",
    "        \"\"\"\n",
    "        Merge two clusters and return merged cluster.\n",
    "        \"\"\"\n",
    "#         print(X[IND_IND],Y[IND_IND])\n",
    "        merged_cluster = [[], []]\n",
    "        merged_cluster[VEC_IND].extend(X[VEC_IND])\n",
    "        merged_cluster[VEC_IND].extend(Y[VEC_IND])\n",
    "        merged_cluster[IND_IND].extend(X[IND_IND])\n",
    "        merged_cluster[IND_IND].extend(Y[IND_IND])\n",
    "#         print(\"merged:\",merged_cluster[IND_IND])\n",
    "        return merged_cluster\n",
    "    \n",
    "    def single_clus_distance(self, X,Y):\n",
    "        \"\"\"\n",
    "        Return single linkage minimum distance.\n",
    "        \n",
    "        Single linkage uses the minimum of the distances between all observations\n",
    "        of the two sets.\n",
    "        \"\"\"\n",
    "        x_fin, y_fin = None, None\n",
    "        min_dist = MIN_DIST\n",
    "#         print(len(X[IND_IND]), len(Y[IND_IND]))\n",
    "        for i in range(0, len(X[IND_IND])):\n",
    "#             print(X[IND_IND][i])\n",
    "            for j in range(0, len(Y[IND_IND])):\n",
    "#                 print(Y[IND_IND][j])\n",
    "                if min_dist >= self._dist_mat[X[IND_IND][i]][Y[IND_IND][j]]:\n",
    "#                     print(\"dist_mat\",X[IND_IND][i],Y[IND_IND][j],self._dist_mat[X[IND_IND][i]][Y[IND_IND][j]])\n",
    "                    min_dist = self._dist_mat[X[IND_IND][i]][Y[IND_IND][j]]\n",
    "                    x_fin, y_fin = i,j\n",
    "#         print(\"fin\",x_fin,y_fin, min_dist)\n",
    "        return min_dist\n",
    "    \n",
    "    def fit(self, X_arr):\n",
    "        \"\"\"\n",
    "        Method to call to fit data.\n",
    "        \"\"\"\n",
    "        init_clusters = [[[X_arr[i]], [i]] for i in range(X_arr.shape[0])]\n",
    "        self.distance_matrix(X_arr)\n",
    "        total_cur_clusters = X_arr.shape[0]\n",
    "        while True:\n",
    "            print(f\"Number of clusters: {total_cur_clusters}\", end='\\r')\n",
    "            clus_to_merge = None\n",
    "            total_cur_clusters -= 1\n",
    "            min_dist = MIN_DIST\n",
    "            for i in range(total_cur_clusters):\n",
    "                for j in range(i+1, total_cur_clusters):\n",
    "                    cur_dist = self.single_clus_distance(init_clusters[i], init_clusters[j])\n",
    "                    if min_dist >= cur_dist:\n",
    "                        min_dist = cur_dist\n",
    "                        clus_to_merge = [i,j]\n",
    "#             print(\"min dist: \", min_dist, clus_to_merge[0], clus_to_merge[1])\n",
    "            init_clusters.append(self.merge_clusters(init_clusters[clus_to_merge[0]], init_clusters[clus_to_merge[1]]))\n",
    "            for index in sorted(clus_to_merge, reverse=True):\n",
    "                del init_clusters[index]\n",
    "            if total_cur_clusters==8:\n",
    "                break\n",
    "        self._results = init_clusters\n",
    "#         print(init_clusters)\n",
    "        self.save()\n",
    "    \n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Save the results in a sorted manner to ../clusters/agglomerative.txt\n",
    "        \"\"\"\n",
    "        sorted_results = sorted(self._results, key= lambda x: min(x[IND_IND]))\n",
    "        sorted_results = [sorted(x[IND_IND]) for x in sorted_results]\n",
    "#         print(sorted_results)\n",
    "        with open(self._path, 'w') as f_open:\n",
    "            for result in sorted_results:\n",
    "                f_open.write(','.join([str(x) for x in result]))\n",
    "                f_open.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters: 900\r"
     ]
    }
   ],
   "source": [
    "agglo = AgglomerativeClustering()\n",
    "agglo.fit(tfidf_matrix.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Assignment_3",
   "language": "python",
   "name": "assignment_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
